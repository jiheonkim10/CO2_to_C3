{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "import gamchanger as gc\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from json import load\n",
    "import joblib\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/CO2-to-C3/src\"))\n",
    "from ml_tools import filter_max_jtarget\n",
    "from gamchanger_tools import create_gam_feature_df\n",
    "from utils.help_utils import get_data_df\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = \"~/data\"   # Directory path where you stored the data â€“ Dataset available at https://doi.org/10.5281/zenodo.15107045\n",
    "\n",
    "pb_df = get_data_df(data_path, \"Pourbaix_phase.xlsx\")\n",
    "ocp_df = get_data_df(data_path, \"OCP_Eads.xlsx\")\n",
    "all_compositions_featurized_df = get_data_df(data_path, \"Compositions_featurized.csv\", ['e1', 'e2', 'e3'])\n",
    "co2r_df = get_data_df(data_path, \"CO2R_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #0] Preprocess CO2R data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2r_df[f'j_C3H6'] = co2r_df['current_density'] * co2r_df['FE_C3H6_mean'] / 100\n",
    "co2r_df_processed = filter_max_jtarget(co2r_df, 'C3H6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #1] EBM model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TRAINing Parameters\n",
    "batch_train = [0,]      # e.g., [0] or [0, 1] .... [0, 1, 2, 3, 4, 5].  Batch 0 means the seed dataset\n",
    "cutoff = 0.05           # Target product (C3H6) cut-off crrent density (see Supplementary Fig. 3a bottom)\n",
    "\n",
    "millers = [(1,0,0), (2,1,1)]\n",
    "species_columns = ['*OCHO','*COOH','CO*COH-2*CO','*CHO-*CO','*C-*CHO']\n",
    "\n",
    "random_seed = 10\n",
    "\n",
    "train_cols = ['e1', 'e2', 'e3'] + ['f1', 'f2', 'f3'] + ['has_e1', 'has_e2', 'has_e3'] +\\\n",
    "             ['ele1_' + x for x in species_columns] + ['ele2_' + x for x in species_columns] + ['ele3_' + x for x in species_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DataFrame\n",
    "\n",
    "co2r_df_train = co2r_df_processed[co2r_df_processed['batch'].isin(batch_train)]\n",
    "print(f\"Train size: {co2r_df_train['composition'].nunique()}\")\n",
    "\n",
    "feature_df = create_gam_feature_df(co2r_df_train, ocp_df, millers = millers)\n",
    "\n",
    "train_df = pd.merge(feature_df, co2r_df_train, on='composition')\n",
    "\n",
    "train_df['j_C3H6_log10'] = train_df['j_C3H6'].apply(lambda x: np.nan if x == 0 else np.log10(x))\n",
    "train_df['j_binary'] = train_df['j_C3H6_log10'].apply(lambda x: True if x > np.log10(cutoff) else False)\n",
    "# Properly fillna for GAM\n",
    "selected_columns = [col for col in train_df.columns if col not in ['e1', 'e2', 'e3', 'j_C3H6']]\n",
    "train_df[selected_columns] = train_df[selected_columns].fillna(0)\n",
    "\n",
    "X_train = train_df[train_cols].copy()\n",
    "y_train = train_df['j_binary'].copy()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space\n",
    "param_grid = {\n",
    "    'max_leaves': [2, 3],\n",
    "    'smoothing_rounds': [50, 75],\n",
    "    'learning_rate': [0.005, 0.015],\n",
    "    'interactions': [0, 0.9]\n",
    "}\n",
    "\n",
    "# Define the EBM model\n",
    "ebm = ExplainableBoostingClassifier(feature_names=train_cols, n_jobs=-2, random_state=random_seed)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ebm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Use accuracy as the scoring metric\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available CPUs\n",
    "    verbose=2  # Display progress during the search\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the best model on the entire training dataset\n",
    "best_ebm = grid_search.best_estimator_\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_ebm, f\"./EBM_models/ebm_trainBATCH{batch_train}.joblib\")\n",
    "\n",
    "# Output the best parameters and scores\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #2] Visualize & Edit & Save - EBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAM Visualization & Edit Feature Importance & Save Edited Model\n",
    "best_ebm = joblib.load(f\"./ebm_models/ebm_trainBATCH{batch_train}.joblib\")\n",
    "ebm_weights_dict = gc.get_model_data(best_ebm)\n",
    "gc.visualize(best_ebm, X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "'''\n",
    "Detailed shape function edit records are in Supplementary Note 5 and Supplementary Table 3.\n",
    "\n",
    "Save the edited model with name of 'trainBATCH{batch_train}_EDITED.gamchanger'\n",
    "e.g., 'trainBATCH[0]_EDITED.gamchanger' or 'trainBATCH[0, 1, 2, 3, 4, 5]_EDITED.gamchanger'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #3] Get Next Batch Suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the edited EBM model\n",
    "ebm_weights_dict_edited = load(open(f\"./gamchanger_files/trainBATCH{batch_train}_EDITED.gamchanger\"))\n",
    "best_ebm_edited = gc.get_edited_model(best_ebm, ebm_weights_dict_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for all compositions\n",
    "prediction_df = all_compositions_featurized_df.copy()\n",
    "# Properly fillna for GAM\n",
    "selected_columns = [col for col in prediction_df.columns if col not in ['e1', 'e2', 'e3']]\n",
    "prediction_df[selected_columns] = prediction_df[selected_columns].fillna(0)\n",
    "\n",
    "prediction_df['j_binary_pred'] = best_ebm_edited.predict(prediction_df[train_cols])\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextBatch_suggestion_df = prediction_df[['composition_nominal', 'j_binary_pred']]\n",
    "\n",
    "nextBatch_suggestion_df.to_csv(f\"./nextBatch_suggestion/BATCH[{max(batch_train)+1}]_suggestion.csv\", index=False)\n",
    "print(f'Batch{max(batch_train)+1} suggestion saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #4] Run HT-Experiment (based on the selected compositions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [STEP #5] EBM Model Comparison (based on the new Batch Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TESTing Parameters\n",
    "batch_new = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DataFrame\n",
    "\n",
    "co2r_df_test = co2r_df_processed[co2r_df_processed['batch'] == batch_new]\n",
    "print(f\"Test size: {co2r_df_test['composition'].nunique()}\")\n",
    "\n",
    "feature_df = create_gam_feature_df(co2r_df_test, ocp_df, millers = millers)\n",
    "\n",
    "test_df = pd.merge(feature_df, co2r_df_test, on='composition')\n",
    "\n",
    "test_df['j_C3H6_log10'] = test_df['j_C3H6'].apply(lambda x: np.nan if x == 0 else np.log10(x))\n",
    "test_df['j_binary'] = test_df['j_C3H6_log10'].apply(lambda x: True if x > np.log10(cutoff) else False)\n",
    "# Properly fillna for GAM\n",
    "selected_columns = [col for col in test_df.columns if col not in ['e1', 'e2', 'e3', 'j_C3H6']]\n",
    "test_df[selected_columns] = test_df[selected_columns].fillna(0)\n",
    "\n",
    "X_test = test_df[train_cols].copy()\n",
    "y_test = test_df['j_binary'].copy()\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Predicted vs. Actual Value: w/o Domain Knowledge-based edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tested on Test Batch\n",
    "y_pred_test_wo_edit = best_ebm.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test_wo_edit)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_test_wo_edit)\n",
    "f1 = f1_score(y_test, y_pred_test_wo_edit)\n",
    "accuracy = accuracy_score(y_test, y_pred_test_wo_edit)\n",
    "\n",
    "fig, (ax_metrics, ax_cm) = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "ax_metrics.axis('off')\n",
    "ax_metrics.text(0.5, 0.5, f'ROC AUC: {roc_auc:.3f}\\nF1 Score: {f1:.3f}\\nAccuracy: {accuracy:.3f}', \n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "\n",
    "# Plot confusion matrix\n",
    "im = ax_cm.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax_cm.set_title(f'Confusion Matrix', fontsize=18)\n",
    "\n",
    "# Add value annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax_cm.text(j, i, format(cm[i, j], 'd'),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# Set labels\n",
    "ax_cm.set_xlabel('Predicted label', fontsize=12)\n",
    "ax_cm.set_ylabel('Actual label', fontsize=12)\n",
    "ax_cm.set_xticks([0, 1])\n",
    "ax_cm.set_yticks([0, 1])\n",
    "ax_cm.set_xticklabels(['False', 'True'], fontsize=12)\n",
    "ax_cm.set_yticklabels(['False', 'True'], fontsize=12)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(im, ax=ax_cm)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predicted vs. Actual Value: after Domain Knowledge-based edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_test_edited = best_ebm_edited.predict(X_test)\n",
    "\n",
    "# Analysis\n",
    "cm = confusion_matrix(y_test, y_pred_test_edited)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_test_edited)\n",
    "f1 = f1_score(y_test, y_pred_test_edited)\n",
    "accuracy = accuracy_score(y_test, y_pred_test_edited)\n",
    "\n",
    "# Plot\n",
    "fig, (ax_metrics, ax_cm) = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "ax_metrics.axis('off')\n",
    "ax_metrics.text(0.5, 0.5, f'ROC AUC: {roc_auc:.3f}\\nF1 Score: {f1:.3f}\\nAccuracy: {accuracy:.3f}', \n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=20)\n",
    "\n",
    "im = ax_cm.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax_cm.set_title('Confusion Matrix', fontsize=18)\n",
    "\n",
    "# Add value annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax_cm.text(j, i, format(cm[i, j], 'd'),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# Set labels\n",
    "ax_cm.set_xlabel('Predicted label', fontsize=12)\n",
    "ax_cm.set_ylabel('True label', fontsize=12)\n",
    "ax_cm.set_xticks([0, 1])\n",
    "ax_cm.set_yticks([0, 1])\n",
    "ax_cm.set_xticklabels(['False', 'True'], fontsize=12)\n",
    "ax_cm.set_yticklabels(['False', 'True'], fontsize=12)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(im, ax=ax_cm)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jk_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
