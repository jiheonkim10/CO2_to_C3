{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/CO2-to-C3/src\"))\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import uniform, randint\n",
    "from bo_tools import expected_improvement, random_selection_from_top_EIvalues\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bayesopt_grid = pd.read_csv(\"~/data/BayesOpt_grid.csv\") # BayesOpt_grid.csv available at https://doi.org/10.5281/zenodo.15107045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of compositions: \", len(bayesopt_grid))\n",
    "bayesopt_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_models = 10\n",
    "TARGET = 'log10_jC3H6_grid'\n",
    "\n",
    "experiments = 10\n",
    "\n",
    "initial_BATCH = [0]     # Batch 0 means seed dataset\n",
    "BATCH_SIZE = 6\n",
    "iteration = 150\n",
    "\n",
    "random_sampling_ratio = 0.75\n",
    "alpha = 0.5 # for Acquisition function (EI)\n",
    "\n",
    "species_columns = ['*OCHO','*COOH','CO*COH-2*CO','*CHO-*CO','*C-*CHO']\n",
    "train_cols = ['f1', 'f2', 'f3'] +\\\n",
    "            ['ele1_' + x for x in species_columns] +\\\n",
    "            ['ele2_' + x for x in species_columns] +\\\n",
    "            ['ele3_' + x for x in species_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in range(experiments):\n",
    "\n",
    "    seeds = [random.randint(0, 10001) for _ in range(number_of_models + 1)]\n",
    "\n",
    "    print(f'Experiment {exp+1} (Random Seeds:{seeds})')\n",
    "\n",
    "    if not initial_BATCH:\n",
    "        if BATCH_SIZE == 1:\n",
    "            initial_df = bayesopt_grid.sample(n=2, random_state=seeds[0]).copy()\n",
    "        else:\n",
    "            initial_df = bayesopt_grid.sample(n=BATCH_SIZE, random_state=seeds[0]).copy()\n",
    "    else:\n",
    "        initial_df = bayesopt_grid.loc[bayesopt_grid['batch'].isin(initial_BATCH)].copy()\n",
    "\n",
    "    max_value_list = []\n",
    "\n",
    "    searched_new_compositions_in_each_iteration = []\n",
    "\n",
    "    for i in range(iteration):\n",
    "\n",
    "        if i == 0:\n",
    "            screened_df = initial_df.copy()\n",
    "\n",
    "        # Prepare Ensemble XGBoost models\n",
    "        ensemble_models = []\n",
    "        for j in range(number_of_models):\n",
    "\n",
    "            param_dist = {\n",
    "                'n_estimators': randint(50, 500),\n",
    "                'max_depth': randint(2, 10),\n",
    "                'learning_rate': uniform(0.01, 0.3),\n",
    "                'subsample': uniform(0.6, 0.4),\n",
    "                'colsample_bytree': uniform(0.6, 0.4),\n",
    "                'min_child_weight': randint(1, 7),\n",
    "                'gamma': uniform(0, 0.5),\n",
    "                'reg_alpha': uniform(0, 1),\n",
    "                'reg_lambda': uniform(0, 1)\n",
    "            }\n",
    "\n",
    "            base_model = XGBRegressor(\n",
    "                missing=np.nan,\n",
    "                random_state=seeds[0],\n",
    "                eval_metric='rmse',\n",
    "                callbacks=[EarlyStopping(rounds=5, save_best=True, maximize=False)] # Early stopping - Suhas\n",
    "            )\n",
    "\n",
    "            if len(screened_df) < int(np.floor(5/random_sampling_ratio)): # CV=2 if the number of data is less than 5\n",
    "                cv = 2\n",
    "            else:\n",
    "                cv = 5\n",
    "\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=base_model,\n",
    "                param_distributions=param_dist,\n",
    "                n_iter=50,      # Number of parameter settings sampled \n",
    "                cv=cv,          # 5-fold cross validation\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,      # Use all available cores\n",
    "                verbose=0,      # Low verbosity or use '2'\n",
    "                random_state=seeds[0]\n",
    "            )\n",
    "\n",
    "            # Random sampling from training dataset (i.e., screened_df)\n",
    "\n",
    "\n",
    "            X_train = screened_df.sample(n=int(len(screened_df) * random_sampling_ratio + 0.5), \n",
    "                                         random_state=seeds[j+1], replace=True)[train_cols].copy()\n",
    "            y_train = screened_df.loc[X_train.index][TARGET].copy()\n",
    "\n",
    "            # Splitting into training and validation sets for early stopping\n",
    "            X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "                X_train, y_train, test_size=0.2, random_state=seeds[j + 1]\n",
    "            )\n",
    "\n",
    "            # random_search.fit(X_train, y_train)\n",
    "            random_search.fit(X_train_split, y_train_split, eval_set=[(X_val_split, y_val_split)], early_stopping_rounds=5, verbose=False)\n",
    "\n",
    "            best_model = random_search.best_estimator_\n",
    "\n",
    "            ensemble_models.append(best_model)\n",
    "\n",
    "        # Prediction for rest of the compositions\n",
    "\n",
    "        remaining_df = bayesopt_grid[~bayesopt_grid.isin(screened_df.to_dict(orient='list')).all(axis=1)]\n",
    "\n",
    "        X_search = remaining_df[train_cols].copy()\n",
    "        mu_list = []\n",
    "\n",
    "        for k in range(number_of_models):\n",
    "\n",
    "            best_model = ensemble_models[k]\n",
    "\n",
    "            mu = best_model.predict(X_search)\n",
    "            mu_list.append(mu)\n",
    "\n",
    "        mu_array = np.array(mu_list)\n",
    "\n",
    "        mean_values = np.mean(mu_array, axis=0)\n",
    "        std_values = np.std(mu_array, axis=0)\n",
    "\n",
    "        # Calculate EI\n",
    "        max_value = screened_df[TARGET].max()\n",
    "\n",
    "        ei = expected_improvement(mean_values, std_values, max_value, alpha=alpha)\n",
    "\n",
    "        # Randomly select compositions based on HIGH EI values\n",
    "\n",
    "        rand_idx = random_selection_from_top_EIvalues(ei, n=BATCH_SIZE, seed=seeds[0])\n",
    "\n",
    "        selected_next_compositions = []\n",
    "        for idx in rand_idx:\n",
    "            composition = remaining_df.iloc[idx]['composition_nominal']\n",
    "            selected_next_compositions.append(composition)\n",
    "            add_df = remaining_df[remaining_df['composition_nominal'] == composition]\n",
    "            screened_df = pd.concat([screened_df, add_df], axis=0)\n",
    "\n",
    "        new_max_value = screened_df[TARGET].max()\n",
    "\n",
    "        max_value_list.append(10**new_max_value)\n",
    "        searched_new_compositions_in_each_iteration.append(selected_next_compositions)\n",
    "\n",
    "        print(f\"Experiment {exp+1} - Iteration {i+1} (#ofExp. = {len(screened_df)}) - New MAX value: {10**new_max_value} ({selected_next_compositions})\")\n",
    "\n",
    "    result_df = pd.DataFrame({'iteration': range(1,iteration+1), 'max_value': max_value_list, 'screened_compositions': searched_new_compositions_in_each_iteration})\n",
    "    result_df.to_csv(f\"BO_BatchSize{BATCH_SIZE}_{TARGET}_Iter_{iteration}_Initial_{initial_BATCH}_exp{exp+10}_Seed_{seeds}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jk_default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
